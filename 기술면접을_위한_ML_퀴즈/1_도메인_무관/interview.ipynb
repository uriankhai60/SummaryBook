{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e9c046",
   "metadata": {},
   "source": [
    "# Q-001) 중심극한정리에 대해서 알고있나요? 개념을 말씀해주시겠어요?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358a186",
   "metadata": {},
   "source": [
    "## 짧은 답변  \n",
    "미지의 분포가 있을때, 무한에 가까운 N번의 샘플링을 해서 샘플들에 대한 평균을 계산하면  \n",
    "\"샘플 평균의 분포\"는 실제 분포와 상관 없이 가우시안 분포를 이룬다는 정리입니다.  \n",
    "  \n",
    "이 정리의 핵심은 모분포의 형상에 관계없이 우리는 모분포의 평균을 신뢰도 있게 예측가능하다는 의미와 같습니다.  \n",
    "\n",
    "  \n",
    "## 긴 답변  \n",
    "상황을 가정해보겠습니다.  \n",
    "쿠키 공장에서 정규분포가 아닌 쿠키들이 만들어졌다고 가정해보겠습니다.  \n",
    "우리가 한번에 쿠키를 n개씩 잡아서 N번 평균을 내면  \n",
    "우리는 쿠키 공장에서 생산된 쿠키들의 평균값을 예측할 수 있습니다.  \n",
    "수식적으로 n이 클수록 정규 분포에 가까워집니다.  \n",
    "\n",
    "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FlGw0i%2FbtqYIjO5S12%2FAAAAAAAAAAAAAAAAAAAAAGOViZK1KUod4reKhqNIkSnQE7f4stZA6MdcF9YRpa9-%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1764514799%26allow_ip%3D%26allow_referer%3D%26signature%3DSIPpiJnm32WWL7InrSjEbKQmVkI%253D)  \n",
    "  \n",
    "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FZqsUi%2FbtqYN2TgxTw%2FAAAAAAAAAAAAAAAAAAAAAOQBBXssGiShtG_89HqGoQz-tWXjPpZ4hceeNm-j1H98%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1764514799%26allow_ip%3D%26allow_referer%3D%26signature%3D956zAn4ZJ2enaqoEeo43Ecj8z3c%253D)  \n",
    "  \n",
    "## 읽을거리  \n",
    "[친절한 데이터 사이언티스트 되기 강좌](https://recipesds.tistory.com/entry/%EC%A4%91%EC%8B%AC%EA%B7%B9%ED%95%9C%EC%A0%95%EB%A6%AC%EC%97%90-%EB%8C%80%ED%95%9C-%EC%98%A4%ED%95%B4-%EB%A7%8E%EC%9C%BC%EB%A9%B4-%EB%AC%B4%EC%A1%B0%EA%B1%B4-%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC-OK): 개념을 소개하는 양질의 글입니다  \n",
    "[통계의 본질 EOSatistics](https://www.youtube.com/watch?v=IY2CiqC3t-g): 영상 설명자료입니다.  \n",
    "\n",
    "\n",
    "## 추가질문  \n",
    "- 혹시 이 개념을 디퓨전과 연관지어 설명하실 수 있나요?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb320c5",
   "metadata": {},
   "source": [
    "# Q-002) 딥러닝 학습에서 데이터에서 피처 정규화가 필요한 이유는 무엇입니까?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d49424",
   "metadata": {},
   "source": [
    "## 답변  \n",
    "수치형 피처들은 각기 단위나 범위가 다르기 때문에,\n",
    "그냥 그대로 모델에 넣으면 스케일이 큰 피처가 너무 큰 영향을 주게 됩니다.\n",
    "\n",
    "예를 들어,\n",
    "한 변수는 0~1 사이인데,\n",
    "다른 변수는 0~10000이라면\n",
    "거리 계산을 하는 모델(k-NN, SVM 등)에서는 큰 숫자를 가진 변수가\n",
    "전체 결과를 거의 좌우하게 되죠.\n",
    "\n",
    "또한 경사하강법을 사용하는 모델(선형회귀, 로지스틱회귀, 신경망 등)은\n",
    "Adaptive Optimizer를 사용하지 않는다면 파라미터에 동일한 학습률을 적용하기 때문에,\n",
    "스케일이 큰 피처는 기울기 변화가 커서 빠르게 움직이고,\n",
    "작은 피처는 천천히 변하게 됩니다.\n",
    "이러면 학습이 불안정해지고,\n",
    "최적점을 찾기까지 오래 걸릴 수 있습니다.\n",
    "\n",
    "그래서 보통은 모든 피처를 비슷한 범위로 맞춰주는 정규화(normalization) 를 해줍니다.\n",
    "이렇게 하면 학습이 더 안정되고 빠르게 수렴하고,\n",
    "특정 피처에 편향되지 않은 모델을 만들 수 있습니다.\n",
    "  \n",
    "## 읽을거리  \n",
    "[블로그](https://markbyun.tistory.com/entry/DL-Feature-Normalization-Methods)\n",
    "\n",
    "\n",
    "## 추가질문  \n",
    "* BatchNorm, LayerNorm, L2 Norm의 수식과 차이점에 대해서 설명할 수 있습니까?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d22fda",
   "metadata": {},
   "source": [
    "# Q-003) 배치(미니배치)로 나어 학습하는 이유는 무엇인가요? 메모리가 무한이면 모든 데이터를 하나의 배치로 학습하는것이 좋을까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbbdc60",
   "metadata": {},
   "source": [
    "## 답변  \n",
    "그렇지 않습니다.  \n",
    "미니배치 학습이 더욱 유리합니다.  \n",
    "딥러닝에서 해결하려고하는 문제는 완벽한 convex임을 보장하지 않으며,  \n",
    "수집한 데이터가 모든 모집단임을 전제로 하지 않는 경우가 대부분입니다.  \n",
    "  \n",
    "그렇기 때문에 collected data를 같은 배치에 넣고 update하는 방법은  \n",
    "한 지점으로 update되는 gradient의 방향과 크기를 만들게 되고  \n",
    "이 경우 모델이 saddle point 혹은 flat region에 머무르게하는 현상을 만들 수 있습니다.  \n",
    "  \n",
    "반면 mini-batch로 학습을 진행하게 되면  \n",
    "iter에서 사용하는 데이터 표본이 달라  \n",
    "gradient의 방향과 크기에 자연스러운 노이즈(stochasticity)가 생기고  \n",
    "이 노이즈 덕분에 딥러닝 함수가 saddle point, plateau에  \n",
    "빠지는 현상은 일어나지 않습니다.  \n",
    "  \n",
    "즉, 미니배치 학습은  \n",
    "딥러닝 최적화의 비선형 지형에서 더 나은 탐색 성질을 가지며,  \n",
    "현실적으로 더 안정적이고 일반화 성능이 높은 방법입니다.  \n",
    "그렇기 때문에 메모리가 무한이라고 하더라도 하나의 배치로 학습하는것은 좋은 방향이 아닙니다.   \n",
    "  \n",
    "## 읽을거리  \n",
    "[블로그1](https://g3lu.tistory.com/14?utm_source=chatgpt.com)  \n",
    "[블로그2](https://bruders.tistory.com/91?utm_source=chatgpt.com)  \n",
    "[블로그3](https://gooopy.tistory.com/69?utm_source=chatgpt.com)  \n",
    "  \n",
    "## 추가질문  \n",
    "* 특정 문제를 접하게 되었을때, 당신은 어떻게 최적의 배치사이즈를 찾습니까?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad420e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

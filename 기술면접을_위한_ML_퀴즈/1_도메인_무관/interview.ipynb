{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e9c046",
   "metadata": {},
   "source": [
    "# Q-001) 중심극한정리에 대해서 알고있나요? 개념을 말씀해주시겠어요?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358a186",
   "metadata": {},
   "source": [
    "## 짧은 답변  \n",
    "미지의 분포가 있을때, 무한에 가까운 N번의 샘플링을 해서 샘플들에 대한 평균을 계산하면  \n",
    "\"샘플 평균의 분포\"는 실제 분포와 상관 없이 가우시안 분포를 이룬다는 정리입니다.  \n",
    "  \n",
    "이 정리의 핵심은 모분포의 형상에 관계없이 우리는 모분포의 평균을 신뢰도 있게 예측가능하다는 의미와 같습니다.  \n",
    "\n",
    "  \n",
    "## 긴 답변  \n",
    "상황을 가정해보겠습니다.  \n",
    "쿠키 공장에서 정규분포가 아닌 쿠키들이 만들어졌다고 가정해보겠습니다.  \n",
    "우리가 한번에 쿠키를 n개씩 잡아서 N번 평균을 내면  \n",
    "우리는 쿠키 공장에서 생산된 쿠키들의 평균값을 예측할 수 있습니다.  \n",
    "수식적으로 n이 클수록 정규 분포에 가까워집니다.  \n",
    "\n",
    "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FlGw0i%2FbtqYIjO5S12%2FAAAAAAAAAAAAAAAAAAAAAGOViZK1KUod4reKhqNIkSnQE7f4stZA6MdcF9YRpa9-%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1764514799%26allow_ip%3D%26allow_referer%3D%26signature%3DSIPpiJnm32WWL7InrSjEbKQmVkI%253D)  \n",
    "  \n",
    "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FZqsUi%2FbtqYN2TgxTw%2FAAAAAAAAAAAAAAAAAAAAAOQBBXssGiShtG_89HqGoQz-tWXjPpZ4hceeNm-j1H98%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1764514799%26allow_ip%3D%26allow_referer%3D%26signature%3D956zAn4ZJ2enaqoEeo43Ecj8z3c%253D)  \n",
    "  \n",
    "## 읽을거리  \n",
    "[친절한 데이터 사이언티스트 되기 강좌](https://recipesds.tistory.com/entry/%EC%A4%91%EC%8B%AC%EA%B7%B9%ED%95%9C%EC%A0%95%EB%A6%AC%EC%97%90-%EB%8C%80%ED%95%9C-%EC%98%A4%ED%95%B4-%EB%A7%8E%EC%9C%BC%EB%A9%B4-%EB%AC%B4%EC%A1%B0%EA%B1%B4-%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC-OK): 개념을 소개하는 양질의 글입니다  \n",
    "[통계의 본질 EOSatistics](https://www.youtube.com/watch?v=IY2CiqC3t-g): 영상 설명자료입니다.  \n",
    "\n",
    "\n",
    "## 추가질문  \n",
    "- 혹시 이 개념을 디퓨전과 연관지어 설명하실 수 있나요?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb320c5",
   "metadata": {},
   "source": [
    "# Q-002) 딥러닝 학습에서 데이터에서 피처 정규화가 필요한 이유는 무엇입니까?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d49424",
   "metadata": {},
   "source": [
    "## 답변  \n",
    "수치형 피처들은 각기 단위나 범위가 다르기 때문에,\n",
    "그냥 그대로 모델에 넣으면 스케일이 큰 피처가 너무 큰 영향을 주게 됩니다.\n",
    "\n",
    "예를 들어,\n",
    "한 변수는 0~1 사이인데,\n",
    "다른 변수는 0~10000이라면\n",
    "거리 계산을 하는 모델(k-NN, SVM 등)에서는 큰 숫자를 가진 변수가\n",
    "전체 결과를 거의 좌우하게 되죠.\n",
    "\n",
    "또한 경사하강법을 사용하는 모델(선형회귀, 로지스틱회귀, 신경망 등)은\n",
    "Adaptive Optimizer를 사용하지 않는다면 파라미터에 동일한 학습률을 적용하기 때문에,\n",
    "스케일이 큰 피처는 기울기 변화가 커서 빠르게 움직이고,\n",
    "작은 피처는 천천히 변하게 됩니다.\n",
    "이러면 학습이 불안정해지고,\n",
    "최적점을 찾기까지 오래 걸릴 수 있습니다.\n",
    "\n",
    "그래서 보통은 모든 피처를 비슷한 범위로 맞춰주는 정규화(normalization) 를 해줍니다.\n",
    "이렇게 하면 학습이 더 안정되고 빠르게 수렴하고,\n",
    "특정 피처에 편향되지 않은 모델을 만들 수 있습니다.\n",
    "  \n",
    "## 읽을거리  \n",
    "[블로그](https://markbyun.tistory.com/entry/DL-Feature-Normalization-Methods)\n",
    "\n",
    "\n",
    "## 추가질문  \n",
    "* BatchNorm, LayerNorm, L2 Norm의 수식과 차이점에 대해서 설명할 수 있습니까?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d22fda",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

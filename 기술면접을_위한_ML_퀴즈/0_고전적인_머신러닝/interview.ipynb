{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67561593",
   "metadata": {},
   "source": [
    "```bash\n",
    "# 짧은 답변  \n",
    "# 긴 답변  \n",
    "# 읽을만한 글과 영상  \n",
    "# 후속 질문  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee3eda",
   "metadata": {},
   "source": [
    "# Q-001) k-NN 알고리즘에 대해서 간단한 소개와 알고리즘의 장점, 단점에 대해서 설명해주실수 있나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182dbea",
   "metadata": {},
   "source": [
    "# 짧은 답변  \n",
    "1. 알고리즘의 소개  \n",
    "k-NN은 k로 지정한 가장 가까운 거리의 k개의 이웃 데이터를 찾고  \n",
    "이웃 데이터의 값들을 평균(average) 혹은 보팅(voting)으로 예측하는 거리기반 비모수(non-parametric) 알고리즘 입니다.  \n",
    "  \n",
    "2. 장점  \n",
    "구현이 매우 간단하고 직관적입니다.  \n",
    "학습 과정이 없으며 오직 인퍼런스 단계만이 존재합니다.  \n",
    "거리 척도(metric)만 변화시킴으로써 알고리즘 성능 개선이 가능합니다.  \n",
    "\n",
    "3. 단점  \n",
    "노이즈에 민감한 알고리즘 입니다.  \n",
    "모든 데이터에 대해서 거리를 계산하기 때문에 예측까지 시간이 오래걸립니다.  \n",
    "모든 데이터에 대해서 값을 가지고 있어야 하기 때문에 메모리 사용량이 큽니다.  \n",
    "고차원 데이터에서는 차원의 저주로 인해 근접 이웃의 신뢰도가 떨어집니다.   \n",
    "  \n",
    "# 긴 답변  \n",
    "1. 알고리즘의 소개  \n",
    "새로운 입력샘플(테스트 샘플)과 기존 데이터 간의 거리를 계산,  \n",
    "가장 가까운 k개의 이웃 데이터의 특성을 기반으로 예측을 수행하는 비모수적 방법입니다.  \n",
    "회귀(regression)의 경우 이웃값들의 평균(average)를 사용하고  \n",
    "분류(classification)의 경우 투표(voting)방식으로 값을 예측합니다.  \n",
    "이웃 데이터를 판별하는 거리 척도로는 대표적으로 유클리드 거리, 코사인 유사도를 주로 사용합니다.  \n",
    "  \n",
    "2. 장점  \n",
    "알고리즘 구현이 매우 쉽과 직관적입니다.  \n",
    "데이터 분포에 대한 가정이 필요 없습니다.  \n",
    "거리 척도, k의 변경을 통해서 성능 제어가 가능합니다.  \n",
    "결정 경계가 선형, 비선형에 관계없이 잘 동작합니다.  \n",
    "regression과 classification 모두 동일한 알고리즘을 적용이 가능합니다.  \n",
    "  \n",
    "3. 단점  \n",
    "모든 데이터의 계산으로 인해서 데이터의 개수가 많을수록 계산 비용이 커집니다.  \n",
    "노이즈에 민감합니다.  \n",
    "차원의 저주, 쉽게 말해서 고차원 데이터에서 성능이 매우 떨어집니다.  \n",
    "\n",
    "# 후속 질문  \n",
    "* 유클리드 거리, 코사인 유사도에 대해서 조금 더 자세히 설명해주시겠어요? 각 거리는 어떤 장단점이 있나요?  \n",
    "* 만약 내가 소유한 집의 부동산 가격 예측 문제에 대해서 사용했다고 하겠습니다. 어떤식으로 피쳐를 구성하실건가요?  \n",
    "* 당신은 실무에서 이 알고리즘과 유사한 알고리즘을 사용한적이 있습니까? 어떤 문제에 사용해보셨나요?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb715827",
   "metadata": {},
   "source": [
    "# Q-002) k-NN 알고리즘에서 k의 값이 커짐에 따라 boundary line이 어떻게 변경됩니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f893fd4d",
   "metadata": {},
   "source": [
    "# 짧은 답변  \n",
    "k는 이웃의 수를 의미합니다.  \n",
    "k가 작을수록 국소적 패턴(노이즈)에 민감해 경계선이 복잡하고 불규칙해집니다.  \n",
    "k가 커질수록 경계선이 단순하고 부드러워집니다.  \n",
    "  \n",
    "# 긴 답변  \n",
    "k는 모델의 복잡도를 제어하는 하이퍼 파라미터입니다.  \n",
    "k가 작다면 경계선이 매우 세밀하고 복잡해집니다.  \n",
    "한 두개의 노이즈 데이터에 의해서 결정이 되므로 데이터에 매우 민감한 오버핏팅이 발생하기 쉽습니다.  \n",
    "k가 크다면 경계선이 매끄럽고 단순해집니다.  \n",
    "노이즈의 영향에는 다소 둔감해질수 있으나 경계선이 단순해져 과소적합이 발생할 수 있습니다.  \n",
    "다른말로는 국소 패턴을 반영하지 못합니다.  \n",
    "  \n",
    "# 후속 질문  \n",
    "* variance, bias개념에 대해서 알고 있습니까? 만약에 알고 있다면 당신이 말한 답변과 연관지어 설명해주시겠어요?  \n",
    "* 어떻게 k값을 결정하는 것이 가장 좋은 방법이라고 생각하시나요?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cd004",
   "metadata": {},
   "source": [
    "# Q-003) PCA에 대해서 알고있습니까? PCA의 개념과 알고리즘에 대해서 설명해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b531fc",
   "metadata": {},
   "source": [
    "# 짧은 답변  \n",
    "1. PCA의 개념  \n",
    "PCA, 다른말로 주성분 분석이란 많은 변수중에서 정보가 중복된 부분을 압축  \n",
    "데이터의 주요한 패턴을 남기는 차원 축소기법입니다.  \n",
    "쉽게 말해, 원래의 변수들을 선형 결합하면서 가장 큰 분산을 가지는 축(주성분)으로 데이터를 재표현합니다.  \n",
    "이렇게 하면 원래 정보는 최대한 유지하면서 차원 수를 줄일 수 있어,  \n",
    "시각화나 모델 학습시 노이즈를 줄이고 효율을 높일 수 있습니다.  \n",
    "  \n",
    "2. PCA 알고리즘  \n",
    "    1. 데이터를 평균 0으로 정규화 합니다.  \n",
    "    2. 공분산 행렬을 이용하여 변수간의 상관관계를 구합니다.  \n",
    "    3. 공분산 행렬의 고유값과 고유백터를 구합니다.  \n",
    "        * 고유백터: 데이터가 가장 많이 퍼진 방향, 주성분의 축을 의미합니다.  \n",
    "        * 고유값: 그 방향의 중요도를 의미합니다.  \n",
    "    4. 고유값이 큰 순서대로 상위 k개의 주성분을 선택해 원본 데이터를 축(고유백터) 방향으로 투영합니다.  \n",
    "  \n",
    "# 긴 답변  \n",
    "1. PCA의 개념  \n",
    "PCA(주성분 분석)은 데이터의 차원을 줄이되, 그 안의 중요한 정보(분산)을 최대한 유지하는 방법입니다.  \n",
    "쉽게 말해, 다차원 데이터들을 \"더 작은 축으로 요약하는 기술\"입니다.  \n",
    "  \n",
    "예를 들어, 키와 몸무게가 모두 큰 영향을 주는 데이터가 있다고 가정하겠습니다.    \n",
    "키와 몸무게는 서로 상관관계가 높습니다.  \n",
    "PCA는 이처럼 비슷한 정보를 담고 있는 변수들을  \n",
    "PC1=0.3\\*키 + 0.9\\*몸무게와 같이 중복없이 요약된 새로운 축으로 바꿔줍니다.  \n",
    "  \n",
    "다시 한번 말해  \n",
    "상관된 변수 -> 서로 독립적인 축으로 변환  \n",
    "데이터의 분산(정보량)이 가장 큰 방향 -> 첫 번째 주성분  \n",
    "그 다음으로 큰 방향 -> 두 번째 주성분  \n",
    "이처럼 축을 정합니다.  \n",
    "  \n",
    "PCA는 데이터 시각화에 많이 사용하는 고전적인 기법입니다.  \n",
    "  \n",
    "2. PCA 알고리즘  \n",
    "고유값 분해(Eigen decomposition)에 기반합니다.  \n",
    "    1. 각 변수의 평균을 0으로 맞춥니다.  \n",
    "    2. 변수들간의 공분산 행렬을 계산합니다.  \n",
    "    3. 공분산 행렬의 고유백터, 고유값을 구합니다.  \n",
    "        * 고유백터는 주성분의 방향을 의미합니다.  \n",
    "        * 고유값은 방향으로의 분산 크기를 의미합니다.  \n",
    "    4. 주성분 선택 및 투영 합니다.  \n",
    "        * 하이퍼 파라미터 k개의 주성분을 택하여, k차원의 새로운 데이터로 차원을 축소합니다.  \n",
    "\n",
    "3. PCA의 장점  \n",
    "    1. 다른 차원 축소기법들과 동일하게 차원의 저주를 완화시킵니다.  \n",
    "    2. 선형적인 관계를 지닌 피쳐들에게서 매우 좋은 성능을 보장합니다.  \n",
    "    3. 데이터 시각화에 매우 유용합니다.  \n",
    "    4. 축소과정에서 계산된 scale을 역으로 이용해 중요 피처를 해석할 수 있습니다.  \n",
    "  \n",
    "# 읽어볼만한 글과 영상  \n",
    "[공돌이의 수학정리노트](https://youtu.be/YEdscCNsinU?si=_ocL0ktTQNWj0gQ1)  \n",
    "    공분산 행렬의 의미에 대해서 직관적으로 잘 설명하고 있습니다.  \n",
    "    시간이 짧습니다.  \n",
    "[김성범 교수님](https://youtu.be/FhQm2Tc8Kic?si=4cD7AsIGV85mglj-)  \n",
    "    상세하게 잘 나와있습니다.  \n",
    "    다만 시간이 좀 깁니다.  \n",
    "  \n",
    "# 후속 질문  \n",
    "* 몇차원으로 축소할지는 어떻게 판단하실건가요?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9ab19",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
